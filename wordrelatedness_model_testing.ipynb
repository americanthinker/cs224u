{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d24626-de3e-45ff-9e91-329108d44711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "from utils import devdf_generator\n",
    "import pandas as pd\n",
    "import torch\n",
    "import vsm\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "VSM_HOME = os.path.join('data', 'vsmdata')\n",
    "\n",
    "DATA_HOME = os.path.join('data', 'wordrelatedness')\n",
    "\n",
    "def evaluate_pooled_bert(rel_df, layer, pool_func):\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "    bert_weights_name = 'bert-base-uncased'\n",
    "\n",
    "    # Initialize a BERT tokenizer and BERT model based on\n",
    "    # `bert_weights_name`:\n",
    "    tokenizer = BertTokenizer.from_pretrained(bert_weights_name)\n",
    "    model = BertModel.from_pretrained(bert_weights_name)\n",
    "    model = model.to(device)\n",
    "    print(f'Model is on {model.device}')\n",
    "\n",
    "    # Get the vocabulary from `rel_df`:\n",
    "    ##### YOUR CODE HERE\n",
    "    vocab = set(rel_df.word1.values) | set(rel_df.word2.values)\n",
    "    \n",
    "    # Use `vsm.create_subword_pooling_vsm` with the user's arguments:\n",
    "    pooled_df = vsm.create_subword_pooling_vsm(vocab, tokenizer, model, layer=layer, pool_func=pool_func)\n",
    "    \n",
    "    # Return the results of the relatedness evalution:\n",
    "    return vsm.word_relatedness_evaluation(rel_df, pooled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a0f9f0-a014-464e-9ac1-01083426d536",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/haystack/lib/python3.8/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: score variance, dtype: float64)\n",
      "Series([], Name: score variance, dtype: float64)\n",
      "Series([], Name: score variance, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "pooling_function = vsm.mean_pooling\n",
    "dev = pd.read_csv(os.path.join(DATA_HOME, \"cs224u-wordrelatedness-dev.csv\"))\n",
    "highest = devdf_generator(dev, scoring='highest')\n",
    "lowest = devdf_generator(dev, scoring='lowest')\n",
    "average = devdf_generator(dev, scoring='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dca10f-b141-4067-a618-23e1802ff43d",
   "metadata": {},
   "source": [
    "### Series of Experiments using differnt \"hyperparameters\" for BERT pooling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a7897dd-1608-43cd-a954-cab09316a4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 1. Same hypers, different dev datasets\n",
    "scores = {}\n",
    "\n",
    "dev_eval, dev_rho = evaluate_pooled_bert(dev, -1, pooling_function)\n",
    "scores['dev'] = dev_rho\n",
    "\n",
    "highest, highest_rho = evaluate_pooled_bert(highest, -1, pooling_function)\n",
    "scores['highest'] = highest_rho\n",
    "\n",
    "lowest, lowest_rho = evaluate_pooled_bert(lowest, -1, pooling_function)\n",
    "scores['lowest'] = lowest_rho\n",
    "\n",
    "mean, mean_rho = evaluate_pooled_bert(average, -1, pooling_function)\n",
    "scores['mean'] = mean_rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ab37ab4-8903-45eb-8e49-0cbd94670f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dev': 0.23311499452307924,\n",
       " 'highest': 0.24422440155634575,\n",
       " 'lowest': 0.2359034072168557,\n",
       " 'mean': 0.24182501097666576}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ee4d3d1-77cf-43f4-9f13-536d218625a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on cuda:0\n"
     ]
    }
   ],
   "source": [
    "#2 same dev set (highest) different pooling functions\n",
    "pooling_scores = {}\n",
    "\n",
    "min_eval, min_rho = evaluate_pooled_bert(highest, -1, vsm.min_pooling)\n",
    "pooling_scores['min'] = min_rho\n",
    "\n",
    "max_eval, max_rho = evaluate_pooled_bert(highest, -1, vsm.max_pooling)\n",
    "pooling_scores['max'] = max_rho\n",
    "\n",
    "mean_eval, mean_rho = evaluate_pooled_bert(highest, -1, vsm.mean_pooling)\n",
    "pooling_scores['mean'] = mean_rho\n",
    "\n",
    "last_eval, last_rho = evaluate_pooled_bert(average, -1, vsm.last_pooling)\n",
    "pooling_scores['last'] = last_rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2040d4a-b84e-48eb-8167-377828a6a0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 0.24454069661746727,\n",
       " 'max': 0.24005252002267974,\n",
       " 'mean': 0.24422440155634575,\n",
       " 'last': 0.23881398655354832}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e0b8d8-40c0-4a6b-a949-7625ee98f74d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
